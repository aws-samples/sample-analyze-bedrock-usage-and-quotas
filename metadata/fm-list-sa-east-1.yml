models:
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-embed-image-v1
  provider: Amazon
- inference_types:
  - PROVISIONED
  model_id: amazon.titan-embed-image-v1:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: L-26C560CE
        tpd: null
        tpm: L-DE641971
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-embed-text-v2:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: L-9EAB0D12
        tpd: null
        tpm: L-44992E63
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-text-express-v1
  provider: Amazon
- inference_types:
  - PROVISIONED
  model_id: amazon.titan-text-express-v1:0:8k
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: L-A70F1DE3
        tpd: null
        tpm: L-70BE83E9
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-text-lite-v1
  provider: Amazon
- inference_types:
  - PROVISIONED
  model_id: amazon.titan-text-lite-v1:0:4k
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: L-2DC80978
        tpd: null
        tpm: L-8CE99163
  inference_types:
  - ON_DEMAND
  model_id: anthropic.claude-3-haiku-20240307-v1:0
  provider: Anthropic
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: L-F406804E
        tpd: null
        tpm: L-4C35BB2A
  inference_types:
  - ON_DEMAND
  model_id: anthropic.claude-3-sonnet-20240229-v1:0
  provider: Anthropic
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm: L-E5084BBA
        tpd: L-B5C049AE
        tpm: L-9A11C666
  inference_profiles:
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-haiku-4-5-20251001-v1:0
  provider: Anthropic
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm: L-DB84CE56
        tpd: L-BC182137
        tpm: L-27C57EE8
  inference_profiles:
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-sonnet-4-5-20250929-v1:0
  provider: Anthropic
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: L-FF8E7864
        tpd: null
        tpm: L-A2BE277A
  inference_types:
  - ON_DEMAND
  model_id: cohere.embed-english-v3
  provider: Cohere
- inference_types:
  - PROVISIONED
  model_id: cohere.embed-english-v3:0:512
  provider: Cohere
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: cohere.embed-multilingual-v3
  provider: Cohere
- inference_types:
  - PROVISIONED
  model_id: cohere.embed-multilingual-v3:0:512
  provider: Cohere
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm: L-7089DC7D
        tpd: L-795ADAB0
        tpm: L-02DFBB76
  inference_profiles:
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: cohere.embed-v4:0
  provider: Cohere
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: L-D9A35062
        tpd: null
        tpm: L-02D831F1
  inference_types:
  - ON_DEMAND
  model_id: mistral.mistral-7b-instruct-v0:2
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: L-3AF844DB
        tpd: null
        tpm: L-01447289
  inference_types:
  - ON_DEMAND
  model_id: mistral.mistral-large-2402-v1:0
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: L-FD938632
        tpd: null
        tpm: L-490F4D1F
  inference_types:
  - ON_DEMAND
  model_id: mistral.mixtral-8x7b-instruct-v0:1
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: openai.gpt-oss-120b-1:0
  provider: OpenAI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: openai.gpt-oss-20b-1:0
  provider: OpenAI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: L-E880C759
        tpd: null
        tpm: L-B7C52139
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-32b-v1:0
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: L-66EE6E0B
        tpd: null
        tpm: L-92F81E14
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-coder-30b-a3b-v1:0
  provider: Qwen
